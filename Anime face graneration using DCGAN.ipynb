{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-26 16:14:11.049649: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-26 16:14:11.930784: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img, array_to_img\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-26 16:14:17.529761: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-26 16:14:17.631994: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-26 16:14:17.632191: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#   # Create 2 virtual GPUs with 1GB memory each\n",
    "#   try:\n",
    "#     tf.config.set_logical_device_configuration(\n",
    "#         gpus[0],\n",
    "#         [tf.config.LogicalDeviceConfiguration(memory_limit=1024),\n",
    "#          tf.config.LogicalDeviceConfiguration(memory_limit=1024)])\n",
    "#     logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "#     print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPUs\")\n",
    "#   except RuntimeError as e:\n",
    "#     # Virtual devices must be set before GPUs have been initialized\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# for gpu in gpus:\n",
    "#   tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "os - used to handle files using system commands\n",
    "\n",
    "numpy - used to perform a wide variety of mathematical operations on arrays\n",
    "\n",
    "matplotlib - used for data visualization and graphical plotting\n",
    "\n",
    "warnings - used to control and suppress warning messages that may be generated by the Python interpreter or third-party libraries during the execution of a Python program\n",
    "\n",
    "tqdm.notebook - used for adding progress bars to your code in Jupyter Notebook\n",
    "\n",
    "tensorflow - used for various tasks in machine learning and deep learning\n",
    "\n",
    "tensorflow.keras.preprocessing.image - provides a variety of image preprocessing utilities for working with images in TensorFlow\n",
    "\n",
    "tensorflow.keras.models - provides various classes and functions for creating and working with neural network models using the Keras API within TensorFlow\n",
    "\n",
    "tensorflow.keras - provides an interface to build, train, and deploy deep learning models using the Keras API within TensorFlow\n",
    "\n",
    "tensorflow.keras.optimizers - provides a collection of optimization algorithms that can be used to train deep learning models in TensorFlow using the Keras API\n",
    "\n",
    "tensorflow.keras.losses - provides a collection of loss functions that can be used to measure the discrepancy between the predicted and target values during the training of deep learning models using the Keras API within TensorFlow\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR='/home/lagrangian/DEEP/animeface-character-dataset/data'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we will create a list which will contain all the dataset images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load complete image paths to the list\n",
    "image_paths = []\n",
    "for image_name in os.listdir(BASE_DIR):\n",
    "    image_path = os.path.join(BASE_DIR, image_name)\n",
    "    image_paths.append(image_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "os.listdir() function retrieves a list of all files and directories present in the BASE_DIR directory\n",
    "\n",
    "os.path.join() creates the complete path of the image file by joining the base directory path with the image name\n",
    "\n",
    "The resulting image path is then appended to the image_paths list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/lagrangian/DEEP/animeface-character-dataset/data/2705.png',\n",
       " '/home/lagrangian/DEEP/animeface-character-dataset/data/13543.png']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_paths[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21551"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_paths)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_paths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# to display grid of images (7x7)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m20\u001b[39m, \u001b[39m20\u001b[39m))\n\u001b[0;32m----> 3\u001b[0m temp_images \u001b[39m=\u001b[39m image_paths[:\u001b[39m49\u001b[39m]\n\u001b[1;32m      4\u001b[0m index \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m image_path \u001b[39min\u001b[39;00m temp_images:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_paths' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# to display grid of images (7x7)\n",
    "plt.figure(figsize=(20, 20))\n",
    "temp_images = image_paths[:49]\n",
    "index = 1\n",
    "\n",
    "for image_path in temp_images:\n",
    "    plt.subplot(7, 7, index)\n",
    "    img = load_img(image_path)\n",
    "    img = np.array(img)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "SIZE=64\n",
    "ip_channel=3\n",
    "LATENT_DIM = 100\n",
    "# weight initializer\n",
    "WEIGHT_INIT = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
    "def load_face_images(folder_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        image = load_img(image_path, color_mode='rgb', target_size=(SIZE,SIZE))\n",
    "        image = img_to_array(image) / 255.0-0.005\n",
    "        images.append(image)\n",
    "    return np.array(images)\n",
    "\n",
    "folder_path = '/home/lagrangian/DEEP/animeface-character-dataset/data'\n",
    "training_images = load_face_images(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3385c80b82a4c06a80e6cf02be6e9a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21551 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the image and convert to numpy array\n",
    "train_images = [np.array(load_img(path)) for path in tqdm(image_paths)]\n",
    "train_images = np.array(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the array\n",
    "train_images = train_images.reshape(train_images.shape[0], 64, 64, 3).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the images\n",
    "train_images = (train_images - 127.5) / 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.52156866, -0.16078432,  0.10588235],\n",
       "        [ 0.8901961 ,  0.33333334,  0.5294118 ],\n",
       "        [-0.02745098, -0.5921569 , -0.30980393],\n",
       "        ...,\n",
       "        [ 0.90588236,  0.9529412 ,  0.9372549 ],\n",
       "        [ 1.        ,  0.9843137 ,  1.        ],\n",
       "        [ 0.9529412 ,  0.92156863,  0.9529412 ]],\n",
       "\n",
       "       [[ 0.654902  , -0.00392157,  0.27058825],\n",
       "        [ 0.35686275, -0.11372549,  0.13725491],\n",
       "        [-0.42745098, -1.        , -0.7176471 ],\n",
       "        ...,\n",
       "        [ 0.9607843 ,  0.9764706 ,  0.9764706 ],\n",
       "        [ 0.9764706 ,  0.9764706 ,  0.99215686],\n",
       "        [ 0.92941177,  0.96862745,  0.96862745]],\n",
       "\n",
       "       [[ 0.7882353 ,  0.13725491,  0.4117647 ],\n",
       "        [-0.39607844, -0.8509804 , -0.5686275 ],\n",
       "        [-0.07450981, -0.75686276, -0.4117647 ],\n",
       "        ...,\n",
       "        [ 1.        ,  1.        ,  1.        ],\n",
       "        [ 0.92156863,  0.96862745,  0.96862745],\n",
       "        [ 0.94509804,  1.        ,  1.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.78039217,  0.20784314,  0.09803922],\n",
       "        [ 0.77254903,  0.21568628,  0.09803922],\n",
       "        [ 0.45882353, -0.04313726, -0.19215687],\n",
       "        ...,\n",
       "        [ 0.7254902 ,  0.37254903,  0.24705882],\n",
       "        [ 0.8666667 ,  0.54509807,  0.39607844],\n",
       "        [ 1.        ,  0.7176471 ,  0.56078434]],\n",
       "\n",
       "       [[ 0.6784314 ,  0.23921569,  0.07450981],\n",
       "        [ 0.77254903,  0.24705882,  0.11372549],\n",
       "        [ 0.52156866,  0.05882353, -0.09019608],\n",
       "        ...,\n",
       "        [ 0.9137255 ,  0.64705884,  0.56078434],\n",
       "        [ 1.        ,  0.75686276,  0.6313726 ],\n",
       "        [ 0.96862745,  0.7490196 ,  0.6       ]],\n",
       "\n",
       "       [[ 0.7490196 ,  0.24705882,  0.11372549],\n",
       "        [ 0.73333335,  0.2627451 ,  0.12156863],\n",
       "        [ 0.60784316,  0.12156863, -0.01960784],\n",
       "        ...,\n",
       "        [ 0.9529412 ,  0.73333335,  0.58431375],\n",
       "        [ 0.96862745,  0.7490196 ,  0.5921569 ],\n",
       "        [ 0.9607843 ,  0.7019608 ,  0.5372549 ]]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LATENT_DIM = 100\n",
    "# weight initializer\n",
    "WEIGHT_INIT = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
    "CHANNELS = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-27 17:10:51.472429: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-27 17:10:51.472783: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-27 17:10:51.472965: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-27 17:10:52.560306: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-27 17:10:52.560551: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-27 17:10:52.560699: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-27 17:10:52.560841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2073 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32768)             3309568   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 32768)             0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 16, 16, 256)      2097408   \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 32, 32, 128)      524416    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 64, 64, 64)       131136    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 64, 64, 3)         3075      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,065,603\n",
      "Trainable params: 6,065,603\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(name='generator')\n",
    "\n",
    "# 1d random noise\n",
    "model.add(layers.Dense(8 * 8 * 512, input_dim=LATENT_DIM))\n",
    "model.add(layers.ReLU())\n",
    "\n",
    "# convert 1d to 3d\n",
    "model.add(layers.Reshape((8, 8, 512)))\n",
    "\n",
    "# upsample to 16x16\n",
    "model.add(layers.Conv2DTranspose(256, (4, 4), strides=(2, 2), padding='same', kernel_initializer=WEIGHT_INIT))\n",
    "model.add(layers.ReLU())\n",
    "\n",
    "# upsample to 32x32\n",
    "model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', kernel_initializer=WEIGHT_INIT))\n",
    "model.add(layers.ReLU())\n",
    "\n",
    "# upsample to 64x64\n",
    "model.add(layers.Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same', kernel_initializer=WEIGHT_INIT))\n",
    "model.add(layers.ReLU())\n",
    "\n",
    "model.add(layers.Conv2D(CHANNELS, (4, 4), padding='same', activation='tanh'))\n",
    "\n",
    "generator = model\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 64)        3136      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 32, 32, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 128)       131200    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 16, 16, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 8, 128)         262272    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 8, 8, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 8193      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 406,081\n",
      "Trainable params: 405,441\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(name='discriminator')\n",
    "input_shape = (64, 64, 3)\n",
    "alpha = 0.2\n",
    "\n",
    "# create conv layers\n",
    "model.add(layers.Conv2D(64, (4, 4), strides=(2, 2), padding='same', input_shape=input_shape))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.LeakyReLU(alpha=alpha))\n",
    "\n",
    "model.add(layers.Conv2D(128, (4, 4), strides=(2, 2), padding='same', input_shape=input_shape))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.LeakyReLU(alpha=alpha))\n",
    "\n",
    "model.add(layers.Conv2D(128, (4, 4), strides=(2, 2), padding='same', input_shape=input_shape))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.LeakyReLU(alpha=alpha))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "# output class\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "discriminator = model\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN(keras.Model):\n",
    "    def __init__(self, generator, discriminator, latent_dim):\n",
    "        super().__init__()\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.g_loss_metric = keras.metrics.Mean(name='g_loss')\n",
    "        self.d_loss_metric = keras.metrics.Mean(name='d_loss')\n",
    "        \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.g_loss_metric, self.d_loss_metric]\n",
    "    \n",
    "    def compile(self, g_optimizer, d_optimizer, loss_fn):\n",
    "        super(DCGAN, self).compile()\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        \n",
    "    def train_step(self, real_images):\n",
    "        # get batch size from the data\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        # generate random noise\n",
    "        random_noise = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        \n",
    "        # train the discriminator with real (1) and fake (0) images\n",
    "        with tf.GradientTape() as tape:\n",
    "            # compute loss on real images\n",
    "            pred_real = self.discriminator(real_images, training=True)\n",
    "            # generate real image labels\n",
    "            real_labels = tf.ones((batch_size, 1))\n",
    "            # label smoothing\n",
    "            real_labels += 0.05 * tf.random.uniform(tf.shape(real_labels))\n",
    "            d_loss_real = self.loss_fn(real_labels, pred_real)\n",
    "            \n",
    "            # compute loss on fake images\n",
    "            fake_images = self.generator(random_noise)\n",
    "            pred_fake = self.discriminator(fake_images, training=True)\n",
    "            # generate fake labels\n",
    "            fake_labels = tf.zeros((batch_size, 1))\n",
    "            d_loss_fake = self.loss_fn(fake_labels, pred_fake)\n",
    "            \n",
    "            # total discriminator loss\n",
    "            d_loss = (d_loss_real + d_loss_fake) / 2\n",
    "            \n",
    "        # compute discriminator gradients\n",
    "        gradients = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "        # update the gradients\n",
    "        self.d_optimizer.apply_gradients(zip(gradients, self.discriminator.trainable_variables))\n",
    "        \n",
    "        \n",
    "        # train the generator model\n",
    "        labels = tf.ones((batch_size, 1))\n",
    "        # generator want discriminator to think that fake images are real\n",
    "        with tf.GradientTape() as tape:\n",
    "            # generate fake images from generator\n",
    "            fake_images = self.generator(random_noise, training=True)\n",
    "            # classify images as real or fake\n",
    "            pred_fake = self.discriminator(fake_images, training=True)\n",
    "            # compute loss\n",
    "            g_loss = self.loss_fn(labels, pred_fake)\n",
    "            \n",
    "        # compute gradients\n",
    "        gradients = tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        # update the gradients\n",
    "        self.g_optimizer.apply_gradients(zip(gradients, self.generator.trainable_variables))\n",
    "        \n",
    "        # update states for both models\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        \n",
    "        return {'d_loss': self.d_loss_metric.result(), 'g_loss': self.g_loss_metric.result()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_imgs=25, latent_dim=100):\n",
    "        self.num_imgs = num_imgs\n",
    "        self.latent_dim = latent_dim\n",
    "        # create random noise for generating images\n",
    "        self.noise = tf.random.normal([25, latent_dim])\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # generate the image from noise\n",
    "        g_img = self.model.generator(self.noise)\n",
    "        # denormalize the image\n",
    "        g_img = (g_img * 127.5) + 127.5\n",
    "        g_img.numpy()\n",
    "        \n",
    "        fig = plt.figure(figsize=(8, 8))\n",
    "        for i in range(self.num_imgs):\n",
    "            plt.subplot(5, 5, i+1)\n",
    "            img = array_to_img(g_img[i])\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "        # plt.savefig('epoch_{:03d}.png'.format(epoch))\n",
    "        plt.show()\n",
    "        \n",
    "    def on_train_end(self, logs=None):\n",
    "        self.model.generator.save('generator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcgan = DCGAN(generator=generator, discriminator=discriminator, latent_dim=LATENT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_LR = 0.0001 \n",
    "G_LR = 0.0003\n",
    "dcgan.compile(g_optimizer=Adam(learning_rate=G_LR, beta_1=0.5), d_optimizer=Adam(learning_rate=D_LR, beta_1=0.5), loss_fn=BinaryCrossentropy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-27 17:11:21.892249: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1059274752 exceeds 10% of free system memory.\n",
      "2023-08-27 17:11:22.965710: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1059274752 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-27 17:11:26.688955: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-08-27 17:11:26.727050: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-08-27 17:11:28.184534: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.37GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-08-27 17:11:28.405044: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.18GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-08-27 17:11:28.698136: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.22GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-08-27 17:11:28.994398: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f67e400d310 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-08-27 17:11:28.994450: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2023-08-27 17:11:29.024998: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-08-27 17:11:29.263347: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "673/674 [============================>.] - ETA: 0s - d_loss: 0.6043 - g_loss: 2.7528"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-27 17:12:17.291572: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.26GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-08-27 17:12:17.291642: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.20GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-08-27 17:12:17.468336: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.13GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-08-27 17:12:17.680027: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.13GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "674/674 [==============================] - ETA: 0s - d_loss: 0.6036 - g_loss: 2.7543"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-27 17:12:19.859149: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.21GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-08-27 17:12:19.859208: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.32GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2023-08-27 17:12:20.014639: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.16GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 100\n",
    "dcgan.fit(train_images, epochs=N_EPOCHS, callbacks=[DCGANMonitor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "noise = tf.random.normal([1, 100])\n",
    "fig = plt.figure(figsize=(3, 3))\n",
    "# generate the image from noise\n",
    "g_img = dcgan.generator(noise)\n",
    "# denormalize the image\n",
    "g_img = (g_img * 127.5) + 127.5\n",
    "g_img.numpy()\n",
    "img = array_to_img(g_img[0])\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
